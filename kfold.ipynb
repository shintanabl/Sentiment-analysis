{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26bc3b1-bf6a-427b-9e78-3e20e80c2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b41f68d-153b-49e8-9570-cc46ae79489e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Isi</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleartweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-06 05:07:39+00:00</td>\n",
       "      <td>ridwanibnuhasan</td>\n",
       "      <td>@BigAlphaID Sesuai dengan target. Dan mungkin ...</td>\n",
       "      <td>netral</td>\n",
       "      <td>sesuai target dunia ancam resesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-06 04:59:29+00:00</td>\n",
       "      <td>faliqhan</td>\n",
       "      <td>@BigAlphaID Rasanya untuk nyemplung sampe minu...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>nyemplung sampe minus mustahil sih sampe q unt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-06 04:56:21+00:00</td>\n",
       "      <td>COREIndonesia</td>\n",
       "      <td>Lalu bagaimana dengan tahun ini? meskipun dipr...</td>\n",
       "      <td>netral</td>\n",
       "      <td>prediksi tumbuh lambat core indonesia p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-06 04:48:33+00:00</td>\n",
       "      <td>Windutmiy</td>\n",
       "      <td>@garudadidada10 ancaman resesi global yang mem...</td>\n",
       "      <td>netral</td>\n",
       "      <td>ancam resesi global butuh bijak fiskal moneter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-06 04:29:56+00:00</td>\n",
       "      <td>dynarfitrianti1</td>\n",
       "      <td>@garudadidada10 kita pasti mampu melewati rese...</td>\n",
       "      <td>positif</td>\n",
       "      <td>lewat resesi global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-06 04:29:02+00:00</td>\n",
       "      <td>catatankaqihati</td>\n",
       "      <td>RT @Anggita_lung: Dengan pencabutan status PPK...</td>\n",
       "      <td>positif</td>\n",
       "      <td>cabut status ppkm optimis kondisi ekonomi indo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-02-06 04:22:32+00:00</td>\n",
       "      <td>soloposdotcom</td>\n",
       "      <td>Resesi Global Disebut Tak Terlalu Berdampak ke...</td>\n",
       "      <td>netral</td>\n",
       "      <td>resesi global dampak ri respons rhenald kasali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-06 04:17:59+00:00</td>\n",
       "      <td>DdMulyadi2</td>\n",
       "      <td>RT @CoklatBenkBenk: Harga Minyak Diprediksi Je...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>harga minyak prediksi jeblok usd barel analis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-02-06 04:12:19+00:00</td>\n",
       "      <td>Indiah752834981</td>\n",
       "      <td>Itu bukan prestasi nomor 1 didunia tapi byk ne...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>prestasi nomor dunia byk negara resesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-02-06 04:09:38+00:00</td>\n",
       "      <td>Di0nAngelo</td>\n",
       "      <td>RT @CoklatBenkBenk: Harga Minyak Diprediksi Je...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>harga minyak prediksi jeblok usd barel analis ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date             User  \\\n",
       "0  2023-02-06 05:07:39+00:00  ridwanibnuhasan   \n",
       "1  2023-02-06 04:59:29+00:00         faliqhan   \n",
       "2  2023-02-06 04:56:21+00:00    COREIndonesia   \n",
       "3  2023-02-06 04:48:33+00:00        Windutmiy   \n",
       "4  2023-02-06 04:29:56+00:00  dynarfitrianti1   \n",
       "5  2023-02-06 04:29:02+00:00  catatankaqihati   \n",
       "6  2023-02-06 04:22:32+00:00    soloposdotcom   \n",
       "7  2023-02-06 04:17:59+00:00       DdMulyadi2   \n",
       "8  2023-02-06 04:12:19+00:00  Indiah752834981   \n",
       "9  2023-02-06 04:09:38+00:00       Di0nAngelo   \n",
       "\n",
       "                                                 Isi Sentiment  \\\n",
       "0  @BigAlphaID Sesuai dengan target. Dan mungkin ...    netral   \n",
       "1  @BigAlphaID Rasanya untuk nyemplung sampe minu...   negatif   \n",
       "2  Lalu bagaimana dengan tahun ini? meskipun dipr...    netral   \n",
       "3  @garudadidada10 ancaman resesi global yang mem...    netral   \n",
       "4  @garudadidada10 kita pasti mampu melewati rese...   positif   \n",
       "5  RT @Anggita_lung: Dengan pencabutan status PPK...   positif   \n",
       "6  Resesi Global Disebut Tak Terlalu Berdampak ke...    netral   \n",
       "7  RT @CoklatBenkBenk: Harga Minyak Diprediksi Je...   negatif   \n",
       "8  Itu bukan prestasi nomor 1 didunia tapi byk ne...   negatif   \n",
       "9  RT @CoklatBenkBenk: Harga Minyak Diprediksi Je...   negatif   \n",
       "\n",
       "                                          cleartweet  \n",
       "0                   sesuai target dunia ancam resesi  \n",
       "1  nyemplung sampe minus mustahil sih sampe q unt...  \n",
       "2            prediksi tumbuh lambat core indonesia p  \n",
       "3  ancam resesi global butuh bijak fiskal moneter...  \n",
       "4                                lewat resesi global  \n",
       "5  cabut status ppkm optimis kondisi ekonomi indo...  \n",
       "6     resesi global dampak ri respons rhenald kasali  \n",
       "7  harga minyak prediksi jeblok usd barel analis ...  \n",
       "8             prestasi nomor dunia byk negara resesi  \n",
       "9  harga minyak prediksi jeblok usd barel analis ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessing_kfold.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3218dcd8-c0ea-4c65-bfb9-1340845b1ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date            object\n",
       "User            object\n",
       "Isi             object\n",
       "Sentiment     category\n",
       "cleartweet      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype({'Sentiment' : 'category'})\n",
    "df = df.astype({'cleartweet' : 'object'})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88973c0a-7d1f-42cd-b8d3-0df9a0774003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1379)\t1\n",
      "  (0, 1499)\t1\n",
      "  (0, 405)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 1282)\t1\n",
      "  (1, 1282)\t1\n",
      "  (1, 1069)\t1\n",
      "  (1, 1328)\t2\n",
      "  (1, 962)\t1\n",
      "  (1, 995)\t1\n",
      "  (1, 1391)\t1\n",
      "  (1, 1612)\t1\n",
      "  (1, 536)\t1\n",
      "  (1, 1599)\t1\n",
      "  (1, 590)\t1\n",
      "  (1, 1060)\t1\n",
      "  (1, 631)\t1\n",
      "  (2, 1213)\t1\n",
      "  (2, 1588)\t1\n",
      "  (2, 822)\t1\n",
      "  (2, 306)\t1\n",
      "  (2, 604)\t1\n",
      "  (3, 70)\t1\n",
      "  (3, 1282)\t1\n",
      "  (3, 509)\t1\n",
      "  :\t:\n",
      "  (1003, 1174)\t1\n",
      "  (1003, 1296)\t1\n",
      "  (1003, 1537)\t1\n",
      "  (1003, 455)\t1\n",
      "  (1003, 1563)\t1\n",
      "  (1003, 105)\t1\n",
      "  (1003, 472)\t1\n",
      "  (1003, 307)\t1\n",
      "  (1004, 1282)\t4\n",
      "  (1004, 1552)\t1\n",
      "  (1004, 450)\t1\n",
      "  (1004, 609)\t1\n",
      "  (1004, 568)\t1\n",
      "  (1004, 1509)\t1\n",
      "  (1004, 446)\t1\n",
      "  (1005, 1282)\t1\n",
      "  (1005, 1069)\t1\n",
      "  (1005, 1328)\t2\n",
      "  (1005, 962)\t1\n",
      "  (1005, 995)\t1\n",
      "  (1005, 1391)\t1\n",
      "  (1005, 1612)\t1\n",
      "  (1005, 536)\t1\n",
      "  (1005, 1599)\t1\n",
      "  (1005, 590)\t1\n",
      "  (0, 1499)\t0.5925785535800462\n",
      "  (0, 1379)\t0.6481366492939087\n",
      "  (0, 1282)\t0.12324821914195506\n",
      "  (0, 405)\t0.3611834320405549\n",
      "  (0, 70)\t0.2883157064344359\n",
      "  (1, 1612)\t0.3026011120535862\n",
      "  (1, 1599)\t0.23421316144324364\n",
      "  (1, 1391)\t0.2491508230203518\n",
      "  (1, 1328)\t0.5299707647715232\n",
      "  (1, 1282)\t0.05511332848680878\n",
      "  (1, 1069)\t0.3026011120535862\n",
      "  (1, 1060)\t0.2649853823857616\n",
      "  (1, 995)\t0.3026011120535862\n",
      "  (1, 962)\t0.19353449803724793\n",
      "  (1, 631)\t0.24105667016855034\n",
      "  (1, 590)\t0.3026011120535862\n",
      "  (1, 536)\t0.25905726548382957\n",
      "  (2, 1588)\t0.35452540585713466\n",
      "  (2, 1213)\t0.3706643365098564\n",
      "  (2, 822)\t0.5718343982459724\n",
      "  (2, 604)\t0.20705091445257764\n",
      "  (2, 306)\t0.6058506631576465\n",
      "  (3, 1300)\t0.3686734194438028\n",
      "  (3, 1282)\t0.0766790193754217\n",
      "  (3, 977)\t0.4210080786489732\n",
      "  :\t:\n",
      "  (1003, 1173)\t0.28911663036160623\n",
      "  (1003, 1084)\t0.28911663036160623\n",
      "  (1003, 667)\t0.21811222831212004\n",
      "  (1003, 604)\t0.10468391353062517\n",
      "  (1003, 472)\t0.30631508487731485\n",
      "  (1003, 455)\t0.28911663036160623\n",
      "  (1003, 307)\t0.30631508487731485\n",
      "  (1003, 105)\t0.30631508487731485\n",
      "  (1004, 1552)\t0.366875111624993\n",
      "  (1004, 1509)\t0.4058275389036583\n",
      "  (1004, 1282)\t0.27905661069804477\n",
      "  (1004, 609)\t0.38304182963357125\n",
      "  (1004, 568)\t0.4058275389036583\n",
      "  (1004, 450)\t0.38304182963357125\n",
      "  (1004, 446)\t0.4058275389036583\n",
      "  (1005, 1612)\t0.3241106984819867\n",
      "  (1005, 1599)\t0.25086157428133077\n",
      "  (1005, 1391)\t0.2668610393678527\n",
      "  (1005, 1328)\t0.5676423116208286\n",
      "  (1005, 1282)\t0.05903091125575086\n",
      "  (1005, 1069)\t0.3241106984819867\n",
      "  (1005, 995)\t0.3241106984819867\n",
      "  (1005, 962)\t0.20729137746230475\n",
      "  (1005, 590)\t0.3241106984819867\n",
      "  (1005, 536)\t0.2774716546577952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "tvec= CountVectorizer()\n",
    "X_cVec = tvec.fit_transform(df['cleartweet'].values.astype('U'))\n",
    "print(X_cVec)\n",
    "h_tfidf = TfidfTransformer()\n",
    "x_tfidf = h_tfidf.fit_transform(X_cVec)\n",
    "print(x_tfidf)\n",
    "X = df.cleartweet\n",
    "Y = df.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebf8cc8-7db2-42cb-bf06-dc8bd10ad7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.79      0.85      0.82        53\n",
      "      netral       0.86      0.68      0.76        72\n",
      "     positif       0.43      0.68      0.53        19\n",
      "\n",
      "    accuracy                           0.74       144\n",
      "   macro avg       0.69      0.74      0.70       144\n",
      "weighted avg       0.78      0.74      0.75       144\n",
      "\n",
      "confusion matrix:\n",
      " [[45  3  5]\n",
      " [11 49 12]\n",
      " [ 1  5 13]]\n",
      "==================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.81      0.79      0.80        58\n",
      "      netral       0.88      0.73      0.80        59\n",
      "     positif       0.47      0.67      0.55        27\n",
      "\n",
      "    accuracy                           0.74       144\n",
      "   macro avg       0.72      0.73      0.72       144\n",
      "weighted avg       0.77      0.74      0.75       144\n",
      "\n",
      "confusion matrix:\n",
      " [[46  3  9]\n",
      " [ 5 43 11]\n",
      " [ 6  3 18]]\n",
      "==================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.74      0.76      0.75        55\n",
      "      netral       0.81      0.68      0.74        62\n",
      "     positif       0.54      0.70      0.61        27\n",
      "\n",
      "    accuracy                           0.72       144\n",
      "   macro avg       0.70      0.71      0.70       144\n",
      "weighted avg       0.73      0.72      0.72       144\n",
      "\n",
      "confusion matrix:\n",
      " [[42  6  7]\n",
      " [11 42  9]\n",
      " [ 4  4 19]]\n",
      "==================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.75      0.78      0.77        51\n",
      "      netral       0.75      0.70      0.72        63\n",
      "     positif       0.69      0.73      0.71        30\n",
      "\n",
      "    accuracy                           0.74       144\n",
      "   macro avg       0.73      0.74      0.73       144\n",
      "weighted avg       0.74      0.74      0.74       144\n",
      "\n",
      "confusion matrix:\n",
      " [[40  9  2]\n",
      " [11 44  8]\n",
      " [ 2  6 22]]\n",
      "==================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.74      0.82      0.78        60\n",
      "      netral       0.73      0.60      0.66        53\n",
      "     positif       0.71      0.77      0.74        31\n",
      "\n",
      "    accuracy                           0.73       144\n",
      "   macro avg       0.73      0.73      0.73       144\n",
      "weighted avg       0.73      0.73      0.73       144\n",
      "\n",
      "confusion matrix:\n",
      " [[49 10  1]\n",
      " [12 32  9]\n",
      " [ 5  2 24]]\n",
      "==================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.73      0.80      0.77        51\n",
      "      netral       0.82      0.62      0.71        64\n",
      "     positif       0.58      0.79      0.67        28\n",
      "\n",
      "    accuracy                           0.72       143\n",
      "   macro avg       0.71      0.74      0.71       143\n",
      "weighted avg       0.74      0.72      0.72       143\n",
      "\n",
      "confusion matrix:\n",
      " [[41  7  3]\n",
      " [11 40 13]\n",
      " [ 4  2 22]]\n",
      "==================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.74      0.83      0.78        59\n",
      "      netral       0.84      0.63      0.72        59\n",
      "     positif       0.61      0.80      0.69        25\n",
      "\n",
      "    accuracy                           0.74       143\n",
      "   macro avg       0.73      0.75      0.73       143\n",
      "weighted avg       0.76      0.74      0.74       143\n",
      "\n",
      "confusion matrix:\n",
      " [[49  4  6]\n",
      " [15 37  7]\n",
      " [ 2  3 20]]\n",
      "==================================================\n",
      "\n",
      "rata-rata Akurasi: 0.7326007326007326\n",
      "rata-rata Precision: 0.7146890562934446\n",
      "rata-rata Recall: 0.7261389299211658\n",
      "rata-rata f1-score: 0.7261389299211658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=40)\n",
    "X_array = x_tfidf.toarray()\n",
    "def cross_val(estimator):\n",
    "    acc = []\n",
    "    pcs = []\n",
    "    rec = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_array, Y):\n",
    "        X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        sm = SMOTE()\n",
    "        X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "        model = estimator.fit(X_train_oversampled, y_train_oversampled)\n",
    "        y_pred=model.predict(X_test)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, y_pred))\n",
    "        pcs.append(precision_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        rec.append(recall_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        rec.append(f1_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        print(f'confusion matrix:\\n {confusion_matrix(y_test, y_pred)}')\n",
    "        print('==================================================\\n')\n",
    "\n",
    "    print(f'rata-rata Akurasi: {np.mean(acc)}')\n",
    "    print(f'rata-rata Precision: {np.mean(pcs)}')\n",
    "    print(f'rata-rata Recall: {np.mean(rec)}')\n",
    "    print(f'rata-rata f1-score: {np.mean(rec)}')\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "cross_val(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc19fa-b939-4b8a-8158-5b69d369e6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
